{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#python\n",
    "import os\n",
    "\n",
    "#package\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import IPython.display as ipd\n",
    "import librosa.display\n",
    "import scipy.io.wavfile\n",
    "\n",
    "#keras\n",
    "from keras.utils import np_utils\n",
    "\n",
    "#sklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from scipy import signal\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Actor_01', 'Actor_02', 'Actor_03', 'Actor_04', 'Actor_05', 'Actor_06', 'Actor_07', 'Actor_08', 'Actor_09', 'Actor_10', 'Actor_11', 'Actor_12', 'Actor_13', 'Actor_14', 'Actor_15', 'Actor_16', 'Actor_17', 'Actor_18', 'Actor_19', 'Actor_20', 'Actor_21', 'Actor_22', 'Actor_23', 'Actor_24']\n"
     ]
    }
   ],
   "source": [
    "#Data directory\n",
    "dir_list=os.listdir('E:/SER/audio/')\n",
    "dir_list.sort()\n",
    "print(dir_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create Dataframe\n",
    "ravdess_db=pd.DataFrame(columns=['path','source','actor','gender','emotion','emotion_lb'])\n",
    "count=0\n",
    "for i in dir_list:\n",
    "    file_list=os.listdir('E:/SER/audio/'+i)\n",
    "    for f in file_list:\n",
    "        nm=f.split('.')[0].split('-')\n",
    "        path='E:/SER/audio/'+i+'/'+f\n",
    "        actor=int(nm[-1])\n",
    "        emotion=int(nm[2])\n",
    "        source=\"Ravdess\"\n",
    "            \n",
    "        if int(actor)%2==0:\n",
    "            gender=\"female\"\n",
    "        else:\n",
    "            gender=\"male\"\n",
    "            \n",
    "        if nm[3]=='01':\n",
    "            intensity=0\n",
    "        else:\n",
    "            intensity=1\n",
    "            \n",
    "        if nm[4]=='01':\n",
    "            statement=0\n",
    "        else:\n",
    "            statement=1\n",
    "            \n",
    "        if nm[5]=='01':\n",
    "            repeat=0\n",
    "        else:\n",
    "            repeat=1\n",
    "            \n",
    "        if emotion==1:\n",
    "            lb=\"neutral\"\n",
    "        elif emotion==2:\n",
    "            lb=\"calm\"\n",
    "        elif emotion==3:\n",
    "            lb=\"happy\"\n",
    "        elif emotion==4:\n",
    "            lb=\"sad\"\n",
    "        elif emotion==5:\n",
    "            lb=\"angry\"\n",
    "        elif emotion==6:\n",
    "            lb=\"fearful\"\n",
    "        elif emotion==7:\n",
    "            lb=\"disgust\"\n",
    "        elif emotion==8:\n",
    "            lb=\"surprised\"\n",
    "        else:\n",
    "            lb=\"none\"\n",
    "            \n",
    "        ravdess_db.loc[count]=[path,source,actor,gender,emotion,lb]\n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>source</th>\n",
       "      <th>actor</th>\n",
       "      <th>gender</th>\n",
       "      <th>emotion</th>\n",
       "      <th>emotion_lb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E:/SER/audio/Actor_01/03-01-01-01-01-01-01.wav</td>\n",
       "      <td>Ravdess</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E:/SER/audio/Actor_01/03-01-01-01-01-02-01.wav</td>\n",
       "      <td>Ravdess</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E:/SER/audio/Actor_01/03-01-01-01-02-01-01.wav</td>\n",
       "      <td>Ravdess</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E:/SER/audio/Actor_01/03-01-01-01-02-02-01.wav</td>\n",
       "      <td>Ravdess</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E:/SER/audio/Actor_01/03-01-02-01-01-01-01.wav</td>\n",
       "      <td>Ravdess</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "      <td>calm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             path   source actor gender  \\\n",
       "0  E:/SER/audio/Actor_01/03-01-01-01-01-01-01.wav  Ravdess     1   male   \n",
       "1  E:/SER/audio/Actor_01/03-01-01-01-01-02-01.wav  Ravdess     1   male   \n",
       "2  E:/SER/audio/Actor_01/03-01-01-01-02-01-01.wav  Ravdess     1   male   \n",
       "3  E:/SER/audio/Actor_01/03-01-01-01-02-02-01.wav  Ravdess     1   male   \n",
       "4  E:/SER/audio/Actor_01/03-01-02-01-01-01-01.wav  Ravdess     1   male   \n",
       "\n",
       "  emotion emotion_lb  \n",
       "0       1    neutral  \n",
       "1       1    neutral  \n",
       "2       1    neutral  \n",
       "3       1    neutral  \n",
       "4       2       calm  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ravdess_db.sort_values(by='path',inplace=True)\n",
    "ravdess_db.index=range(len(ravdess_db.index))\n",
    "ravdess_db.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ravdess_db['split']=np.where((ravdess_db.actor==23) | (ravdess_db.actor==24), 'Test',\n",
    "                              (np.where((ravdess_db.actor==21) | (ravdess_db.actor==22),'Val', 'Train')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ravdess_db.loc[ravdess_db.emotion_lb=='calm',['emotion','emotion_lb']]=1,'neutral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_db=ravdess_db\n",
    "dataset_db.emotion_lb=dataset_db.gender+\"_\"+dataset_db.emotion_lb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_duration=3\n",
    "sampling_rate=44100\n",
    "input_length=sampling_rate * audio_duration\n",
    "n_mfcc = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sample = np.zeros(input_length)\n",
    "MFCC = librosa.feature.mfcc(data_sample, sr=sampling_rate, n_mfcc=n_mfcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal, sample_rate = librosa.load(dataset_db.path[0], res_type='kaiser_fast',sr=sampling_rate)\n",
    "signal,index = librosa.effects.trim(signal,top_db = 25)\n",
    "signal = scipy.signal.wiener(signal)\n",
    "\n",
    "if len(signal) > input_length:\n",
    "    signal = signal[0:input_length]\n",
    "elif  input_length > len(signal):\n",
    "    max_offset = input_length - len(signal)  \n",
    "    signal = np.pad(signal, (0, max_offset), \"constant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = np.array(signal).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2254b1cf29a4da9aaec30d603aea8a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1440), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ayush\\AppData\\Roaming\\Python\\Python37\\site-packages\\scipy\\signal\\signaltools.py:974: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  res *= (1 - noise / lVar)\n",
      "C:\\Users\\ayush\\AppData\\Roaming\\Python\\Python37\\site-packages\\scipy\\signal\\signaltools.py:974: RuntimeWarning: invalid value encountered in multiply\n",
      "  res *= (1 - noise / lVar)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "audios= np.empty(shape=(dataset_db.shape[0],128, MFCC.shape[1], 1))\n",
    "\n",
    "count=0\n",
    "for i in tqdm(range(len(dataset_db))):\n",
    "    signal, sample_rate = librosa.load(dataset_db.path[i], res_type='kaiser_fast',sr=sampling_rate)\n",
    "    signal,index = librosa.effects.trim(signal,top_db = 25)\n",
    "    signal = scipy.signal.wiener(signal)\n",
    "    \n",
    "    if len(signal) > input_length:\n",
    "        signal = signal[0:input_length]\n",
    "    elif  input_length > len(signal):\n",
    "        max_offset = input_length - len(signal)  \n",
    "        signal = np.pad(signal, (0, max_offset), \"constant\")\n",
    "\n",
    "    melspec = librosa.feature.melspectrogram(signal, sr=sample_rate, n_mels=128,n_fft=2048,hop_length=512)   \n",
    "    logspec = librosa.amplitude_to_db(melspec)\n",
    "    logspec = np.expand_dims(logspec, axis=-1)\n",
    "    audios[count,] = logspec \n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200, 128, 259, 1) (1200,)\n"
     ]
    }
   ],
   "source": [
    "x_train=audios[(dataset_db['split']=='Train')]\n",
    "y_train=dataset_db.emotion_lb[(dataset_db['split']=='Train')]\n",
    "\n",
    "print(x_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 128, 259, 1) (120,)\n"
     ]
    }
   ],
   "source": [
    "x_test=audios[(dataset_db['split']=='Val')]\n",
    "y_test=dataset_db.emotion_lb[(dataset_db['split']=='Val')]\n",
    "\n",
    "print(x_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=np.array(x_train)\n",
    "y_train=np.array(y_train)\n",
    "x_test=np.array(x_test)\n",
    "y_test=np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb=LabelEncoder()\n",
    "y_train=np_utils.to_categorical(lb.fit_transform(y_train))\n",
    "y_test=np_utils.to_categorical(lb.fit_transform(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_traincnn=x_train\n",
    "x_testcnn=x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1200, 128, 259, 1), (120, 128, 259, 1), (1200, 14), (120, 14))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_traincnn.shape,x_testcnn.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 259, 1)\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "num_classes=len(np.unique(np.argmax(y_train,1)))\n",
    "input_shape=x_traincnn.shape[1:]\n",
    "print(input_shape)\n",
    "learning_rate=0.0001\n",
    "decay = 1e-6\n",
    "momentum=0.9\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
